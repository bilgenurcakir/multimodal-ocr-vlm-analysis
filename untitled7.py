# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/163TQp8Ps-V_htyB0-XcBc0M0hHbZevCe
"""

# OCR için
!pip install easyocr

# Torch ve torchvision (VLM için)
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Transformers (CLIP modeli için)
!pip install transformers

# Görüntü işlemleri ve gösterim
!pip install matplotlib pillow

# Tablo / CSV işlemleri
!pip install pandas

from google.colab import files
uploaded = files.upload()

# Yüklenen görsellerin isimlerini listeleme
img_names = list(uploaded.keys())
print("Yüklenen görseller:", img_names)

import easyocr
from PIL import Image
import matplotlib.pyplot as plt

# OCR reader
reader = easyocr.Reader(['tr', 'en'])

ocr_results = {}

for img_name in img_names:
    # Görseli aç
    image = Image.open(img_name).convert("RGB")

    # OCR çalıştır
    result = reader.readtext(img_name)
    ocr_text = " ".join([res[1] for res in result])
    ocr_results[img_name] = ocr_text

    # Görseli göster ve altına OCR metni yazdır
    plt.figure(figsize=(10,6))
    plt.imshow(image)
    plt.axis('off')
    plt.title(f"OCR sonucu:\n{ocr_text}", fontsize=12)
    plt.show()



!pip install transformers torch torchvision pillow

from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

# Model ve processor
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

vlm_results = {}

for img_name in img_names:
    image = Image.open(img_name).convert("RGB")

    # Görseli işlemden geçir
    inputs = processor(images=image, return_tensors="pt")
    out = model.generate(**inputs)
    caption = processor.decode(out[0], skip_special_tokens=True)

    vlm_results[img_name] = caption

    # Görsel ve açıklamayı göster
    plt.figure(figsize=(10,6))
    plt.imshow(image)
    plt.axis('off')
    plt.title(f"VLM Açıklaması:\n{caption}", fontsize=12)
    plt.show()

# Her görsel için birleşik sonuçları saklayacak sözlük
combined_results = {}

for img_name in img_names:
    combined_results[img_name] = {
        "ocr_text": ocr_results[img_name],
        "vlm_context": vlm_results[img_name],
        "combined": f"Görsel bir '{vlm_results[img_name]}' ve üzerinde şu metinler var: {ocr_results[img_name]}"
    }

# Örnek olarak birleşik yorumları yazdırma
for img_name in img_names:
    print(f"Görsel: {img_name}")
    print("Birleşik yorum:")
    print(combined_results[img_name]['combined'])
    print("-"*50)

for img_name in img_names:
    print(f"Görsel: {img_name}")
    print("Sadece OCR ile:")
    print(combined_results[img_name]['ocr_text'])
    print("OCR + VLM birleşik analiz:")
    print(combined_results[img_name]['combined'])
    print("="*70)